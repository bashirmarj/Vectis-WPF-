"""
production_feature_recognizer.py
=================================

Main orchestrator for complete feature recognition system.

Version: 2.3 - Classification Fix
Target Accuracy: 70-80%

CHANGES IN v2.3:
- âœ… Fixed classification logic - run recognizers first, then classify
- âœ… Classifier now receives feature_dict as required

CHANGES IN v2.2:
- âœ… Disabled location-based deduplication for turning features
- âœ… Turning features already semantically merged, don't need location dedup
- âœ… Fixes step over-deduplication issue

Features:
- Integrates all recognizers
- Memory management
- Error handling
- Confidence scoring
- Manufacturing validation
"""

from production_hole_recognizer import ProductionHoleRecognizer
from production_pocket_recognizer import ProductionPocketRecognizer
from production_slot_recognizer import ProductionSlotRecognizer
from production_turning_recognizer import ProductionTurningRecognizer
from production_part_classifier import ProductionPartClassifier, PartFamily

from OCC.Extend.DataExchange import read_step_file
from typing import List, Dict, Optional
import logging
import time
import psutil
import os

logger = logging.getLogger(__name__)


class ProductionFeatureRecognizer:
    """
    Complete production feature recognition system.
    
    Usage:
        recognizer = ProductionFeatureRecognizer()
        result = recognizer.recognize("part.step")
    """

    def __init__(self, 
                 memory_limit_mb: int = 2000,
                 time_limit_sec: float = 60.0):
        """
        Initialize recognizers with resource limits.
        
        Args:
            memory_limit_mb: Maximum memory usage (MB)
            time_limit_sec: Maximum processing time (seconds)
        """
        self.memory_limit_mb = memory_limit_mb
        self.time_limit_sec = time_limit_sec
        
        # Initialize recognizers
        self.hole_recognizer = ProductionHoleRecognizer()
        self.pocket_recognizer = ProductionPocketRecognizer()
        self.slot_recognizer = ProductionSlotRecognizer()
        self.turning_recognizer = ProductionTurningRecognizer()
        self.classifier = ProductionPartClassifier()
        
        logger.info("âœ… Production Feature Recognizer v2.3 initialized")
        logger.info(f"   Memory limit: {memory_limit_mb}MB")
        logger.info(f"   Time limit: {time_limit_sec}s")

    def recognize(self, step_file_path: str) -> Dict:
        """
        Main entry point: Recognize all features in STEP file.
        
        Args:
            step_file_path: Path to STEP/IGES file
            
        Returns:
            Dict with success, features, confidence, etc.
        """
        start_time = time.time()
        
        try:
            # Check file exists
            if not os.path.exists(step_file_path):
                return self._error_result(f"File not found: {step_file_path}")

            logger.info(f"ðŸ” Analyzing: {os.path.basename(step_file_path)}")
            
            # Load STEP file
            shape = read_step_file(step_file_path)
            if shape is None:
                return self._error_result("Failed to read STEP file")

            # Run ALL recognizers first (needed for classification)
            holes = []
            pockets = []
            slots = []
            turning_features = []
            rotation_axis = None

            # Try turning recognition first
            logger.info("   ðŸ”„ Checking for turning features...")
            result = self.turning_recognizer.recognize_turning_features(shape)
            turning_features = result.get('features', [])
            rotation_axis = result.get('axis')
            
            # If not rotational, run milling recognizers
            if result.get('part_type') == 'not_rotational':
                logger.info("   â¬œ Prismatic part - running milling recognizers...")
                holes = self.hole_recognizer.recognize_holes(shape)
                pockets = self.pocket_recognizer.recognize_pockets(shape)
                slots = self.slot_recognizer.recognize_slots(shape)
                logger.info(f"   Holes: {len(holes)}, Pockets: {len(pockets)}, Slots: {len(slots)}")
            else:
                logger.info(f"   ðŸ”„ Rotational part - turning features: {len(turning_features)}")
                # Also check for holes on rotational parts (drilled holes are common)
                holes = self.hole_recognizer.recognize_holes(shape)
                logger.info(f"   Holes: {len(holes)}")

            # Build feature dict for classification
            feature_dict = {
                'turning_features': turning_features,
                'holes': holes,
                'pockets': pockets,
                'slots': slots,
                'rotation_axis': rotation_axis
            }
            
            # Classify part based on extracted features
            part_family = self.classifier.classify(shape, feature_dict)
            logger.info(f"   Part family: {part_family.value}")

            # Post-process features
            all_features = holes + pockets + slots + turning_features
            
            # CRITICAL FIX v2.2: Split deduplication by feature type
            # - Holes/pockets/slots: Apply location-based deduplication
            # - Turning features: Skip deduplication (already semantically merged)
            prismatic_features = holes + pockets + slots
            deduplicated_prismatic = self._deduplicate_features(prismatic_features)
            
            # Turning features don't need location dedup - already handled by semantic merger
            deduplicated_turning = turning_features
            
            logger.info(f"ðŸ”§ Post-processing:")
            logger.info(f"   Deduplicated features:")
            logger.info(f"      Holes/pockets/slots: {len(prismatic_features)} â†’ {len(deduplicated_prismatic)}")
            logger.info(f"      Turning: {len(turning_features)} â†’ {len(deduplicated_turning)} (semantic merge only)")
            
            final_features = deduplicated_prismatic + deduplicated_turning
            
            # Calculate confidence
            confidence = self._calculate_confidence(final_features)

            processing_time = time.time() - start_time
            
            logger.info(f"âœ… RECOGNITION COMPLETE")
            logger.info(f"   Total Features: {len(final_features)}")
            logger.info(f"   Confidence: {confidence:.1%}")
            logger.info(f"   Time: {processing_time:.2f}s")

            # Generate feature summary
            feature_summary = {}
            for feat in final_features:
                feat_dict = feat.to_dict() if hasattr(feat, 'to_dict') else feat
                ftype = feat_dict.get('type', 'unknown')
                subtype = feat_dict.get('subtype', '')
                key = f"{ftype}_{subtype}" if subtype else ftype
                feature_summary[key] = feature_summary.get(key, 0) + 1

            logger.info(f"   Feature summary: {feature_summary}")

            return {
                'success': True,
                'features': [f.to_dict() if hasattr(f, 'to_dict') else f for f in final_features],
                'holes': [f.to_dict() if hasattr(f, 'to_dict') else f for f in deduplicated_prismatic if self._is_hole(f)],
                'pockets': [f.to_dict() if hasattr(f, 'to_dict') else f for f in deduplicated_prismatic if self._is_pocket(f)],
                'slots': [f.to_dict() if hasattr(f, 'to_dict') else f for f in deduplicated_prismatic if self._is_slot(f)],
                'turning_features': [f.to_dict() if hasattr(f, 'to_dict') else f for f in deduplicated_turning],
                'num_features': len(final_features),
                'confidence': confidence,
                'part_family': part_family.value,
                'rotation_axis': rotation_axis.tolist() if rotation_axis is not None else None,
                'processing_time_seconds': processing_time,
                'errors': []
            }

        except Exception as e:
            logger.error(f"âŒ Recognition failed: {e}", exc_info=True)
            return self._error_result(str(e))

    def _is_hole(self, feature) -> bool:
        """Check if feature is a hole"""
        feat_dict = feature.to_dict() if hasattr(feature, 'to_dict') else feature
        return feat_dict.get('type') == 'hole'

    def _is_pocket(self, feature) -> bool:
        """Check if feature is a pocket"""
        feat_dict = feature.to_dict() if hasattr(feature, 'to_dict') else feature
        return feat_dict.get('type') == 'pocket'

    def _is_slot(self, feature) -> bool:
        """Check if feature is a slot"""
        feat_dict = feature.to_dict() if hasattr(feature, 'to_dict') else feature
        return feat_dict.get('type') == 'slot'

    def _deduplicate_features(self, features: List) -> List:
        """
        Deduplicate features based on location.
        
        NOTE: This is ONLY for prismatic features (holes, pockets, slots).
        Turning features have their own semantic merging in turning_feature_merger.py
        """
        if not features:
            return features

        # Group by type first
        by_type = {}
        for feat in features:
            feat_dict = feat.to_dict() if hasattr(feat, 'to_dict') else feat
            ftype = feat_dict.get('type', 'unknown')
            if ftype not in by_type:
                by_type[ftype] = []
            by_type[ftype].append(feat)

        deduplicated = []

        for ftype, flist in by_type.items():
            # Location-based deduplication with 0.1mm tolerance
            seen_locations = {}
            
            for feat in flist:
                feat_dict = feat.to_dict() if hasattr(feat, 'to_dict') else feat
                loc = feat_dict.get('location', [0, 0, 0])
                
                # Round to 0.1mm precision
                rounded = tuple(round(x, 1) for x in loc)
                
                if rounded not in seen_locations:
                    seen_locations[rounded] = feat
                    deduplicated.append(feat)
                else:
                    # Merge face indices if available
                    existing = seen_locations[rounded]
                    existing_dict = existing.to_dict() if hasattr(existing, 'to_dict') else existing
                    if 'face_indices' in existing_dict and 'face_indices' in feat_dict:
                        existing_dict['face_indices'].extend(feat_dict['face_indices'])

        return deduplicated

    def _calculate_confidence(self, features: List) -> float:
        """Calculate overall confidence score"""
        if not features:
            return 0.0

        confidences = []
        for feat in features:
            feat_dict = feat.to_dict() if hasattr(feat, 'to_dict') else feat
            confidences.append(feat_dict.get('confidence', 0.7))

        return sum(confidences) / len(confidences)

    def _error_result(self, error_msg: str) -> Dict:
        """Return error result"""
        return {
            'success': False,
            'features': [],
            'holes': [],
            'pockets': [],
            'slots': [],
            'turning_features': [],
            'num_features': 0,
            'confidence': 0.0,
            'part_family': 'unknown',
            'rotation_axis': None,
            'processing_time_seconds': 0.0,
            'errors': [error_msg]
        }


if __name__ == "__main__":
    import sys
    
    logging.basicConfig(level=logging.INFO)
    
    if len(sys.argv) < 2:
        print("Usage: python production_feature_recognizer.py <step_file>")
        sys.exit(1)

    recognizer = ProductionFeatureRecognizer()
    result = recognizer.recognize(sys.argv[1])
    
    print(f"\n{'='*60}")
    print(f"RESULT: {'SUCCESS' if result['success'] else 'FAILED'}")
    print(f"{'='*60}")
    print(f"Features: {result['num_features']}")
    print(f"Confidence: {result['confidence']:.1%}")
    print(f"Part family: {result['part_family']}")
    if result['errors']:
        print(f"Errors: {result['errors']}")
